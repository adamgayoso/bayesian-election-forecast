{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Dynamic Linear Model for Election Forecasting\n",
    "\n",
    "## Adam Gayoso and Srikar Varadaraj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The electoral victory of Donald Trump in November 2016 was widely viewed as an upset victory over Hillary Clinton. Various academic and journalistic sources ran forecasting models for the election, with many giving Clinton over a 90% chance of victory. Here we revisit the election and use a Bayesian dynamic linear model adapated from Linzer and Kremp to develop our own forecast of the election. By incorporating the uncertainty of undecided voters in the polls, we believe that Hillary Clinton had a 70% chance of victory on election night. We will intersperse our model with its corresponding code. The code is essentially a copy from run_model.py in /src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import edward as ed\n",
    "import tensorflow as tf\n",
    "from edward.models import Normal, Binomial\n",
    "from edward.models import MultivariateNormalFullCovariance\n",
    "from scipy.special import logit\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import collections\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from helper import prepare_polls, process_2012_polls\n",
    "from helper import predict_scores, covariance_matrix\n",
    "from plots import generate_time_plot, generate_undecided_plot\n",
    "\n",
    "ELECTION_DATE = dt.date(2016, 11, 8)\n",
    "BURN_IN = 5000\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criticism of 2016 Models\n",
    "\n",
    "The election of Donald Trump came as a surprise to many. Below we see the final forecasted probability ([source](https://www.buzzfeed.com/jsvine/2016-election-forecast-grades?utm_term=.dsWz0w4MY#.rf1MnvgVW)) that Trump wins the electoral college from many of the most popular forecasters.\n",
    "\n",
    "|            Organization           \t| Pr(Trump wins) \t|\n",
    "|:---------------------------------:\t|---------------:\t|\n",
    "|          FiveThirtyEight          \t|           0.29 \t|\n",
    "|             PollSavvy             \t|           0.18 \t|\n",
    "|    The New York Times / Upshot    \t|           0.15 \t|\n",
    "|           Kremp / Slate           \t|           0.10 \t|\n",
    "|         Linzer / Daily Kos        \t|           0.08 \t|\n",
    "|        The Huffington Post        \t|           0.02 \t|\n",
    "| The Princeton Election Consortium \t|           0.01 \t|\n",
    "\n",
    "What most of these organizations failed to take into account was the power of the undecided voter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Dynamic Linear Model for Two-Party Voter Share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The data consists of polls from May 1, 2016 to November 6, 2016. The polls come from the Huffington Post's pollster database and consist of national polls and state polls. A pollster is a firm that gives a poll. We remove any polls that have overlapping dates and are from the same pollster in the same state. Since polls are taken over several days, we calculate the poll date as the midpoint date in the poll's date range. While more than two candidates run for president, we only consider Hillary Clinton and Donald Trump, as well as undecided voters in each poll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "polls = pd.read_csv('../data/all_polls_2016.csv',\n",
    "                    parse_dates=['begin', 'end', 'poll_date'])\n",
    "up_to_t = dt.date(2016, 11, 8)\n",
    "state_polls, national_polls = prepare_polls(polls, up_to_t)\n",
    "\n",
    "# Get prior information from 2012 election\n",
    "prior_diff_score, state_w, ev_states = process_2012_polls()\n",
    "prior_diff_score = prior_diff_score[state_polls.state.unique()]\n",
    "state_weights = state_w[state_polls.state.unique()].as_matrix()\n",
    "state_weights = tf.convert_to_tensor(state_weights, dtype=tf.float32)\n",
    "ev_states = ev_states[state_polls.state.unique()].as_matrix()\n",
    "\n",
    "n_states = len(state_polls.state.unique())\n",
    "n_pollsters = len(polls.pollster.unique())\n",
    "# Week of last poll\n",
    "w_last = state_polls.week_index.max()\n",
    "# Days until election\n",
    "days_until_E = (ELECTION_DATE - state_polls.poll_date.max().date()).days\n",
    "# Election day as index\n",
    "E_day = days_until_E + state_polls.date_index.max()\n",
    "E_week = (ELECTION_DATE + dt.timedelta(days=-1)\n",
    "          ).isocalendar()[1] - polls.week.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Our model is an adaptation of the models of Kremp and Linzer. \n",
    "\n",
    "Polls are binomially distributed with sample size $N_i$.\n",
    "\n",
    "$$ N^{Clinton}_i \\sim \\textrm{Binomial}(N_i, \\pi^{Clinton}_i) $$\n",
    "\n",
    "#### State Poll:\n",
    "\n",
    "$$\\textrm{logit} (\\pi^{Clinton}_i) = \\mu_a[t_i] + \\mu_b^{weekly}[w_t, s] + \\mu_c[p_i]$$\n",
    "\n",
    "There is signal, which are the terms $ \\mu_a$ and  $\\mu_b$, representing a national component shared across all states and a state component, respectively. The other term is noise: pollster house effect ($\\mu_c$). In order to reduce the number of parameters in the model, $\\mu_b$ is treated as a weekly parameter.\n",
    "\n",
    "$w_t$ is the week of day $t$.\n",
    "\n",
    "#### National Poll:\n",
    "\n",
    "$$\\textrm{logit} (\\pi^{Clinton}_i) = \\textrm{logit}\\left( \\sum_{s \\in {1 \\dots S}} \\omega_s \\cdot \\textrm{logit}^{-1} (\\mu_a[t_i] + \\mu_b^{weekly}[w_{t_i}, s]) \\right) + \\alpha + \\mu_c[p_i]$$\n",
    "\n",
    "This is the weighted average of the state polls, weighted by 2012 turnout adjusted for population growth from 2011 and 2015. We have a new term $\\alpha$, which compensates for the difference in the weighted average and the actual poll. \n",
    "\n",
    "\n",
    "We will start backwards from election day, as this is the most intuitive way to understand the model. The model is made up of two components. The forward component covers dates from the last day of polling to election day. The backward component covers days from May 1, 2016 until the last day of polling. The last day of polling could be any time during the election process, so the model could be run every week during the election.\n",
    "\n",
    "#### Latent variables\n",
    "\n",
    "|      Effect     |                  Description |                             Structure |\n",
    "|:---------------:|-----------------------------:|--------------------------------------:|\n",
    "| $\\mu_b$ | Latent state voter intention | One variable for each (week, state) |\n",
    "|    $\\mu_a$    |       Latent national swings |      One variable for each day |\n",
    "|   $\\mu_c$   |         Latent house effects |      One variable for every pollster |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mu_b$ priors\n",
    "\n",
    "State component\n",
    "\n",
    "#### Election day\n",
    "\n",
    "This prior depends on the Time-for-Change model, which is a baseline prediction of the election based on GDP figures, the previous president's party and length of term. This has nothing to do with the two candidates. $48.6\\%$ is the prior from this model. $\\delta_{1 \\dots S}$ represents the difference in Obama's state averages and national average in 2012.\n",
    "\n",
    "Let time $T$ be election day.\n",
    "\n",
    "$$\\mu_b[T, 1 \\dots S] \\sim \\textrm{Multivariate Normal}(\\textrm{logit} (0.486 + \\delta_{1 \\dots S}), \\mathbf{\\Sigma})$$\n",
    "\n",
    "$$\\delta_{1 \\dots S} = \\pi_s^{Obama} - \\pi_*^{Obama}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_b_prior_cov = covariance_matrix(0.05, 0.5, n_states)\n",
    "mu_b_prior_cov = tf.convert_to_tensor(mu_b_prior_cov, dtype=tf.float32)\n",
    "mu_b_prior_mean = logit(0.486 + prior_diff_score).as_matrix()\n",
    "mu_b_prior_mean = tf.convert_to_tensor(mu_b_prior_mean, dtype=tf.float32)\n",
    "mu_b_prior = MultivariateNormalFullCovariance(\n",
    "    loc=mu_b_prior_mean, covariance_matrix=mu_b_prior_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Component $(t \\geq t_{last})$\n",
    "\n",
    "$$\\mu_b^{weekly}[w_t-1, 1 \\dots S] \\sim \\textrm{Multivariate Normal}(\\mu_b^{weekly}[w_t, 1 \\dots S], \\mathbf{\\Sigma_b^{walk}})$$\n",
    "\n",
    "$$\\mathbf{\\Sigma_b^{walk}} = \\textrm{cov-matrix}(\\textrm{var}=0.015^2 \\times 7, \\rho=0.75)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_bs = []\n",
    "mu_bs.append(mu_b_prior)\n",
    "sigma_walk_b_forecast = covariance_matrix(7 * 0.015 ** 2, 0.75, n_states)\n",
    "sigma_walk_b_forecast = tf.convert_to_tensor(\n",
    "    sigma_walk_b_forecast, dtype=tf.float32)\n",
    "for w in range(E_week - state_polls.week_index.max()):\n",
    "    mu_bs.append(MultivariateNormalFullCovariance(\n",
    "        loc=mu_bs[-1], covariance_matrix=sigma_walk_b_forecast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Component $(t < t_{last})$\n",
    "\n",
    "$$\\mu_b^{weekly}[w_t-1, s] \\sim \\textrm{Normal}(\\mu_b^{weekly}[w_t, s], \\sigma_b \\cdot \\sqrt{7})$$\n",
    "\n",
    "$$\\sigma_b = 0.005$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_b = 0.005 * np.sqrt(7) * tf.ones(n_states)\n",
    "for w in range(w_last):\n",
    "    mu_bs.append(Normal(loc=mu_bs[-1], scale=sigma_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mu_a$ Priors\n",
    "\n",
    "National Component\n",
    "\n",
    "$$\\mu_a[t-1] \\sim \\textrm{Normal}(\\mu_a[t], \\sigma_a)$$\n",
    "\n",
    "$$\\mu_a[T] = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_a = 0.025\n",
    "mu_a_buffer = tf.zeros(1, tf.float32)\n",
    "mu_as = []\n",
    "for t in range(E_day):\n",
    "    if t == 0:\n",
    "        mu_as.append(Normal(loc=0.0, scale=sigma_a))\n",
    "    else:\n",
    "        mu_as.append(Normal(loc=mu_as[-1], scale=sigma_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mu_c$ Priors\n",
    "House Effect\n",
    "\n",
    "$$\\mu_c[p] \\sim \\textrm{Normal}(0 , \\sigma_c)$$\n",
    "\n",
    "$$\\sigma_c = 0.05$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_c = 0.05 * tf.ones(n_pollsters)\n",
    "mu_c = Normal(loc=tf.zeros(n_pollsters), scale=sigma_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\alpha$ Prior\n",
    "\n",
    "$$\\alpha \\sim \\textrm{Normal}(\\sum_{s \\in {1 \\dots S}} \\omega_s \\delta_s, \\sigma_{\\alpha})$$\n",
    "\n",
    "$$\\sigma_{\\alpha} = 0.2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_mean = (state_w * prior_diff_score).sum().astype(np.float32)\n",
    "alpha = Normal(loc=alpha_mean, scale=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembly\n",
    "\n",
    "State polls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_b_tf = tf.stack(mu_bs)\n",
    "mu_a_tf = tf.stack(mu_as)\n",
    "mu_a_tf = tf.concat([mu_a_buffer, mu_a_tf], axis=0)\n",
    "# Due to list in reverse\n",
    "mu_a_state = tf.gather(\n",
    "    mu_a_tf, (E_day - state_polls.date_index).as_matrix())\n",
    "state_ind = state_polls[['week_index', 'state_index']].as_matrix()\n",
    "# Due to list in reverse\n",
    "state_ind[:, 0] = E_week - state_ind[:, 0]\n",
    "\n",
    "mu_b_state = tf.gather_nd(mu_b_tf, state_ind)\n",
    "mu_c_state = tf.gather(mu_c, state_polls.pollster_index)\n",
    "\n",
    "state_logits = mu_b_state + mu_a_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "National Polls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nat_ind = national_polls[['week_index', 'date_index']].as_matrix()\n",
    "# Due to list in reverse\n",
    "nat_ind[:, 0] = E_week - nat_ind[:, 0]\n",
    "nat_ind[:, 1] = E_day - nat_ind[:, 1]\n",
    "mu_b_nat = tf.gather(mu_b_tf, nat_ind[:, 0])\n",
    "mu_a_nat = tf.expand_dims(tf.gather(mu_a_tf, nat_ind[:, 1]), 1)\n",
    "# expit\n",
    "nat_expits = 1 / (1 + tf.exp(-1 * (mu_a_nat + mu_b_nat)))\n",
    "# logit\n",
    "nat_weigh_avg = tf.multiply(state_weights, nat_expits)\n",
    "nat_weigh_avg = -tf.log((1 / (tf.reduce_sum(nat_weigh_avg, axis=1))) - 1)\n",
    "nat_weigh_avg += alpha\n",
    "mu_c_nat = tf.gather(mu_c, national_polls.pollster_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood\n",
    "\n",
    "$$ N^{Clinton}_i \\sim \\textrm{Binomial}(N_i, \\pi^{Clinton}_i) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_logits = tf.concat([state_logits, nat_weigh_avg], axis=0)\n",
    "final_logits += tf.concat([mu_c_state, mu_c_nat], axis=0)\n",
    "\n",
    "X = tf.placeholder(tf.float32, len(state_polls) + len(national_polls))\n",
    "y = Binomial(total_count=X, logits=final_logits, value=tf.zeros(\n",
    "    len(state_polls) + len(national_polls), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Hamiltonian Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [100%] ██████████████████████████████ Elapsed: 1057s | Acceptance Rate: 0.636\n"
     ]
    }
   ],
   "source": [
    "others = [mu_c, alpha]\n",
    "latent_variables = mu_bs + mu_as + others\n",
    "n_respondents = np.append(state_polls.n_respondents.as_matrix(\n",
    "), national_polls.n_respondents.as_matrix())\n",
    "n_clinton = np.append(state_polls.n_clinton.as_matrix(),\n",
    "                      national_polls.n_clinton.as_matrix())\n",
    "inference = ed.HMC(latent_variables, data={X: n_respondents, y: n_clinton})\n",
    "inference.run(step_size=0.003, n_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract samples from HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmu_bs = []\n",
    "for b in mu_bs:\n",
    "    qmu_bs.append(inference.latent_vars[b].params.eval())\n",
    "qmu_bs = list(reversed(qmu_bs))\n",
    "\n",
    "qmu_as = []\n",
    "for a in mu_as:\n",
    "    qmu_as.append(inference.latent_vars[a].params.eval())\n",
    "qmu_as = list(reversed(qmu_as))\n",
    "\n",
    "qmu_c = inference.latent_vars[mu_c].params.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Linear Regression for Undecided Voters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "undecided_table = state_polls[['p_undecided', 'date_index', 'state_index']].as_matrix()\n",
    "undecided_table = undecided_table[np.where(undecided_table[:, 0] != 0)[0]]\n",
    "undecided = undecided_table[:, 0]\n",
    "date_index = undecided_table[:, 1].astype(np.int32)\n",
    "state_index = undecided_table[:, 2].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "$$w_s = \\textrm{Normal}(0,  1)$$\n",
    "\n",
    "$$b_s = \\textrm{Normal}(0,  1)$$\n",
    "\n",
    "$$u_s = \\textrm{Normal}(w_s^T t + b,  1)$$\n",
    "\n",
    "$$u_s \\in \\{0, ..., 100\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = Normal(loc=tf.zeros(n_states), scale=tf.ones(n_states))\n",
    "b = Normal(loc=tf.zeros(n_states), scale=tf.ones(n_states))\n",
    "gat_w = tf.gather(w, state_index)\n",
    "gat_b = tf.gather(b, state_index)\n",
    "und = Normal(loc=gat_w * date_index + gat_b, scale=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "KLqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 28s | Loss: 14265.141\n"
     ]
    }
   ],
   "source": [
    "qw = Normal(loc=tf.Variable(tf.random_normal([n_states])), scale=tf.nn.softplus(tf.Variable(tf.random_normal([n_states]))))\n",
    "qb = Normal(loc=tf.Variable(tf.random_normal([n_states])), scale=tf.nn.softplus(tf.Variable(tf.random_normal([n_states]))))\n",
    "inference = ed.KLqp({w: qw, b: qb}, data={und: undecided})\n",
    "inference.run(n_samples=10, n_iter=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_w = qw.mean().eval()\n",
    "mean_b = qb.mean().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plots in ../plots/undecided_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a5309e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "for s in state_polls.state.unique():\n",
    "    generate_undecided_plot(undecided_table, i, s, mean_w, mean_b, E_day, save=True)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pennsylvania Undecided](../plots/undecided_plots/pennsylvania.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for Clinton Share of Two-Party Vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each posterior sample:\n",
    "\n",
    "$$e = \\textrm{Multivariate Normal}(0, \\Sigma)$$\n",
    "\n",
    "$$\\Sigma = \\textrm{cov-matrix}(\\textrm{var}=2, \\rho=0.75)$$\n",
    "\n",
    "$$e = \\textrm{logit}^{-1}(e)$$\n",
    "\n",
    "    For state outcomes:\n",
    "\n",
    "$$\\pi^{clinton}[t,s] = \\textrm{logit}^{-1} (\\mu_a[t] + \\mu_b[w_t, s]) + e[s] \\cdot u_s[t]$$\n",
    "\n",
    "    For national outcome:\n",
    "\n",
    "$$\\pi^{clinton}[t, US] = \\sum_{s \\in S} \\omega_s \\cdot (\\textrm{logit}^{-1} (\\mu_a[t] + \\mu_b[t, s]) + e[s] \\cdot u_s[t])$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_scores = predict_scores(qmu_as, qmu_bs, E_day, mean_w, mean_b, var=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = 'wisconsin'\n",
    "state_s_polls = state_polls[state_polls.state == s]\n",
    "state_scores = predicted_scores[:, :, i]\n",
    "generate_plot(state_scores, state_s_polls, BURN_IN, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Election\n",
    "\n",
    "Here we sample from predicted scores $10^4$ times and calculate:\n",
    "\n",
    "$$\\textrm{EV}^{Clinton} = \\sum_{s \\in S} \\textrm{electoral_votes}[s] \\cdot \\mathbb{1}[\\textrm{predicted_score}[T, s] > 0.5]$$\n",
    "\n",
    "If $\\textrm{EV}^{Clinton} > 270$ she wins that simulation of the election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_scores = predicted_scores[:, BURN_IN:, :]\n",
    "e_day_results = clean_scores[-1, :, :]\n",
    "outcomes = []\n",
    "clinton_wins = 0\n",
    "for i in range(10000):\n",
    "    draw = np.random.randint(0, e_day_results.shape[0])\n",
    "    outcome = e_day_results[draw]\n",
    "    outcome = np.dot(outcome >= 0.5, ev_states)\n",
    "    if outcome > 270:\n",
    "        clinton_wins += 1\n",
    "    outcomes.append(outcome)\n",
    "    \n",
    "x = np.unique(outcomes)\n",
    "freq = collections.Counter(outcomes)\n",
    "height = [freq[s] for s in x]\n",
    "plt.bar(x, height)\n",
    "plt.title('Probability Clinton wins =' + str(clinton_wins / 10000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for s in state_polls.state.unique():\n",
    "    state_s_polls = state_polls[state_polls.state == s]\n",
    "    state_scores = predicted_scores[:, :, i]\n",
    "    generate_plot(state_scores, state_s_polls, BURN_IN, s, save=True)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pennsylvania Time](../plots/time_plots/wisconsin.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
